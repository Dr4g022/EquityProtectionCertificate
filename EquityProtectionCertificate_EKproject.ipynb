{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "In this project we are trying to price an Equity protection certificate, Intesa Sanpaolo MAX LONG CAP CERTIFICATES on MIB ESG DECREMENT 5% (EUR - NR) Index due 31.12.2029 (ISIN code:XS2556920119), using Monte Carlo simulation.\n",
    "But what is an Equity protection certificate? In short gives us the chance to participate to the Long of a certain underlying without incurring in a loss in case markets moves versus us. Gives a protection based on the contract and has a cap level making it similiar to a barrier option.\n",
    "In order to price it we used the following enhancements:\n",
    "-Vasicek model for the evolution of interest rates\n",
    "-Heston model for the evolution of the underlying considering also a stochastic volatility\n",
    "-The computation of the Greeks using numerical approximation which: Delta, Gamma, Vega, Rho and Theta\n",
    "-The antithetic variance reduction\n",
    "-The issuer credit risk using the hazard rates"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SXQ6wAhHw_Bu"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we can see a part of the details of our certificate and some parameters used in Vasicek and Heston Model.\n",
    "Parameters used for short rates and heston are the main cause in change of price of our certificate that can make the price differ even in high amounts from the one priced on the market, but why?\n",
    "The reasons are mainly based on different paramaters used in our models that reflect different market conditions(if no calibration involved):\n",
    "    -The discount factors impacts the price of certificate (inverted yield curve or normal curves, etc.), so the parameters in Vasicek gives us different market realities causing different prices for each market reality\n",
    "    -We can find ourselves in Risk-ON and Risk-OFF markets, highlighted by the presence of high/low volatilities where investors move within different market products causing the rise/fall of different products. Heston model helps us to evolve volatility in time which applied to our underlying gives good estimates of how index moves\n",
    "Since we are using montecarlo simulations, we would need to discretize our formulas and the choice would be between Miler or Euler discretization, in our case we used the Euler discretization (we can see how to do it here: https://frouah.com/finance%20notes/Euler%20and%20Milstein%20Discretization.pdf)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#Certificate details\n",
    "S0 = 763.91  #This is our Initial Reference Value for the underlying\n",
    "issue_price = 1000.0 #This is the nominal of the Equity protection certificate\n",
    "maturity = 7 #Certificate life time\n",
    "\n",
    "#Vasicek parameters\n",
    "r0 = 0.02 #Initial interest spot rate\n",
    "alpha = 0.2 #This is the speed of mean reversion\n",
    "gamma = 0.03 #Long term mean interest rate\n",
    "r_vol = .07  #The volatility of interest rates\n",
    "\n",
    "#Heston parameters\n",
    "kappa = .2 #Mean reversion speed\n",
    "theta = 0.09 #Long-term mean variance under risk-neutral dynamics\n",
    "v0 = 0.4   #Initial squared volatility\n",
    "sigma = 0.5  #VolofVol"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Assumptions we used in order to price:\n",
    "    -Why Vasicek?\n",
    "        Unlike in the past where negative rates were seen by academic/economic figures in bad way and had low rate presence, today we see a different reality where negative rates can happen and can stay so for long times.\n",
    "    -Why Heston?\n",
    "        Heston has some properties that are useful to get a good price estimate, such as: Correlation dynamics between price/volatility, can capture volatility smile thanks to the stochastic volatility presence and is not very difficult to implement with MC.\n",
    "The formulas used for this certificate can be seen in Final Terms documents: https://www.intesasanpaolo.prodottiequotazioni.com/EN/Download/Asset?id=2a3f7a80-aa22-470d-a662-0626f6489359.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def MCS(S0, issue_price, r0, alpha, gamma, r_vol, kappa, theta, v0, maturity, sigma, n_simulations, n_paths):\n",
    "    cap_percentage = 1\n",
    "    cap_level = S0 * cap_percentage #it will be equal to IRV\n",
    "    multiplier = issue_price / S0\n",
    "    participation_factor = 1\n",
    "    initial_percentage = 1\n",
    "    T = maturity #years\n",
    "    premium_percentage = 0.0393\n",
    "    premium_gearing = 2\n",
    "    M = n_simulations\n",
    "    N = n_paths\n",
    "    np.random.seed(232)   #This is our seed used to generate the random normal numbers\n",
    "    dt = 1 / N\n",
    "    corr_matrix = np.array([[1.0, 0.5, 0.2],  #Here we have the correlation matrix, starting from first row we have: r/r, r/s and r/v\n",
    "                            [0.5, 1.0, 0.3],\n",
    "                            [0.2, 0.3, 1.0]])\n",
    "    cholesky_factor = np.linalg.cholesky(corr_matrix) #Cholesky decomposition gives us as a result a lower triangular matrix that we use for the distribution correlations\n",
    "    total_payoffs = [] #Qui creamo un vettore di payoffs per rendere più facile il calcolo della varianza/media\n",
    "    years = np.arange(1, T+1, 1)\n",
    "    mean = 0\n",
    "\n",
    "    for i in range(M):\n",
    "        r = r0\n",
    "        S = S0\n",
    "        V = v0\n",
    "        sum_r = 0\n",
    "        payoff = 0\n",
    "        discounted_payoffs = 0\n",
    "        discount_issue_price = 0\n",
    "        for y in years:\n",
    "            for s in range(N):\n",
    "                Z_r = np.random.normal(0.0, 1.0) #Our random normal, I put in parenthesis mean 0.0 and variance 1.0 just to be sure he gives me this output\n",
    "                Z_s = np.random.normal(0.0, 1.0)\n",
    "                Z_v = np.random.normal(0.0, 1.0)\n",
    "                eta_r = Z_r * cholesky_factor[0, 0]\n",
    "                eta_s = Z_r * cholesky_factor[1, 0] + Z_s * cholesky_factor[1, 1]\n",
    "                eta_v = Z_r * cholesky_factor[2, 0] + Z_s * cholesky_factor[2, 1] + Z_v * cholesky_factor[2, 2]\n",
    "\n",
    "                #Stochastic Vasicek\n",
    "                r = r + alpha * (gamma - r) * dt + r_vol * np.sqrt(dt) * eta_r\n",
    "                sum_r += r\n",
    "\n",
    "                #Heston underlying\n",
    "                S = S * math.exp((r-0.5*V)*dt + np.sqrt(V) * np.sqrt(dt)* eta_s)\n",
    "\n",
    "                # Apply stochastic volatility based on Heston model\n",
    "                V = V + kappa*(theta-V)*dt + sigma * np.sqrt(V)*np.sqrt(dt) * eta_v\n",
    "                if V<0:\n",
    "                    V=abs(V) #We need to avoid negative V, and we use a reflection here that gives us absolute value in case of negative V\n",
    "\n",
    "            #Here we have the calculation of our yearly coupons (called premium remuneration) that pays us based on underlying performance\n",
    "            if y in years:\n",
    "                participation_remuneration = issue_price * np.maximum(0, premium_percentage * (1 + premium_gearing * ((S - S0)/S0)))\n",
    "                payoff += participation_remuneration\n",
    "            #This is the final amount that the investor receveis at maturity\n",
    "            if y == maturity:\n",
    "                settlement_amount = np.minimum(cap_level, np.maximum(initial_percentage * S0, (S0 + 1 * (S - S0) * multiplier))) * 1\n",
    "                payoff += settlement_amount\n",
    "            #Trapezoidal rule for the short rates that we use after to get the discount factors and discount our payoffs (coupon + settlement amount)\n",
    "            integral_r=(0.5*(r0-r) + sum_r) * dt\n",
    "            discount_factor = np.exp(-integral_r)\n",
    "            discounted_payoffs = payoff * discount_factor\n",
    "\n",
    "        total_payoffs.append(discounted_payoffs)\n",
    "\n",
    "    variance = np.std(total_payoffs)\n",
    "    mean = np.mean(total_payoffs)\n",
    "    MC_error = np.sqrt(variance/M)\n",
    "    mean, variance, MC_error\n",
    "\n",
    "    #print(\"Price\", mean)\n",
    "    #print(\"Standard error\", std_error)\n",
    "    return mean"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The price we get has a difference of 2€ from the one in the market which is a very good result.\n",
    "Why our price is so near the real price?\n",
    "    Means that the parameters we chose reflects exactly or near the market conditions we are in. Obviously for better results we would like to calibrate our model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "1015.6580269116268"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here we can recall our function and put the different paramaters for our models and certificate details in order to price the certificate\n",
    "MCS(763.91, 1000, .02, 0.2, .03, .07, .2, 0.09, 0.4, 7, .5, 1000, 250)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we have our issuer credit risk. In order to compute and make this function I followed the idea of Hazard Rates presented in the book \"Options, Futures and other Derivates\" by Hull on page 563.\n",
    "Since Intesa san paolo credit rating is BBB, years and avg_hazard_rates were extracted from table 24.1 and used in the function in order to discount the price given my our MC simulation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def issuer_credit_risk(price, maturity):\n",
    "    years = [1, 2, 3, 4, 5, 7, 10, 15]\n",
    "    avg_hazard_rates = [0.0016, 0.0045, 0.0078, 0.0117, 0.0158, 0.0233, 0.0332, 0.0469]\n",
    "    count = 0\n",
    "    if maturity not in years:\n",
    "        raise ValueError(\"Invalid maturity. Available options are: \" + \", \".join(str(year) for year in years))\n",
    "    else:\n",
    "        for i in years:\n",
    "            if i == maturity:\n",
    "                count += 1\n",
    "            default_probability = 1 - math.exp(-avg_hazard_rates[count]*maturity)\n",
    "        adjusted_price = price * (1 - default_probability)\n",
    "\n",
    "    return adjusted_price\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "984.1634429270154"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price = MCS(763.91, 1000, .02, 0.2, .03, .07, .2, 0.09, 0.4, 7, .5, 1000, 250)\n",
    "issuer_credit_risk(price, 7) #Price adjusted by the Hazard rates\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def MCS_antithetic(S0, issue_price, r0, alpha, gamma, r_vol, kappa, theta, v0, maturity, sigma, n_simulations, n_paths):\n",
    "    cap_percentage = 1\n",
    "    cap_level = S0 * cap_percentage #it will be equal to IRV\n",
    "    multiplier = issue_price / S0\n",
    "    participation_factor = 1\n",
    "    initial_percentage = 1\n",
    "    T = maturity #years\n",
    "    premium_percentage = 0.0393\n",
    "    premium_gearing = 2\n",
    "    M = n_simulations\n",
    "    N = n_paths\n",
    "    np.random.seed(232)\n",
    "    dt = 1 / N\n",
    "    corr_matrix = np.array([[1.0, 0.5, 0.2],\n",
    "                            [0.5, 1.0, 0.3],\n",
    "                            [0.2, 0.3, 1.0]])\n",
    "    cholesky_factor = np.linalg.cholesky(corr_matrix)\n",
    "    total_payoffs_anti = []\n",
    "    total_payoffs = [] #Qui creamo un vettore di payoffs per rendere più facile il calcolo della varianza media\n",
    "    years = np.arange(1, T+1, 1)\n",
    "    mean = 0\n",
    "\n",
    "    for i in range(M):\n",
    "        r_anti = r0\n",
    "        S_anti = S0\n",
    "        V_anti = v0\n",
    "        sum_r_anti = 0\n",
    "        payoff_anti = 0\n",
    "        discounted_payoffs_anti = 0\n",
    "        discount_issue_price_anti = 0\n",
    "        r = r0\n",
    "        S = S0\n",
    "        V = v0\n",
    "        sum_r = 0\n",
    "        payoff = 0\n",
    "        discounted_payoffs = 0\n",
    "        discount_issue_price = 0\n",
    "        for y in years:\n",
    "            for s in range(N):\n",
    "                Z_r = np.random.normal(0.0, 1.0)\n",
    "                Z_s = np.random.normal(0.0, 1.0)\n",
    "                Z_v = np.random.normal(0.0, 1.0)\n",
    "                eta_r = Z_r * cholesky_factor[0, 0]\n",
    "                eta_s = Z_r * cholesky_factor[1, 0] + Z_s * cholesky_factor[1, 1]\n",
    "                eta_v = Z_r * cholesky_factor[2, 0] + Z_s * cholesky_factor[2, 1] + Z_v * cholesky_factor[2, 2]\n",
    "\n",
    "                #antithetic variables\n",
    "                Z_r_anti = -(np.random.normal(0.0, 1.0))\n",
    "                Z_s_anti = -(np.random.normal(0.0, 1.0))\n",
    "                Z_v_anti = -(np.random.normal(0.0, 1.0))\n",
    "                eta_r_anti = Z_r_anti * cholesky_factor[0, 0]\n",
    "                eta_s_anti = Z_r_anti * cholesky_factor[1, 0] + Z_s_anti * cholesky_factor[1, 1]\n",
    "                eta_v_anti = Z_r_anti * cholesky_factor[2, 0] + Z_s_anti * cholesky_factor[2, 1] + Z_v_anti * cholesky_factor[2, 2]\n",
    "\n",
    "\n",
    "                r = r + alpha * (gamma - r) * dt + r_vol * np.sqrt(dt) * eta_r\n",
    "                sum_r = sum_r + r\n",
    "\n",
    "                r_anti = r_anti + alpha * (gamma - r_anti) * dt + r_vol * np.sqrt(dt) * eta_r_anti\n",
    "                sum_r_anti = sum_r_anti + r_anti\n",
    "\n",
    "                # Apply stochastic volatility based on Heston model\n",
    "                V = V + kappa*(theta-V)*dt + sigma *np.sqrt(V)*np.sqrt(dt)*eta_v\n",
    "                if V < 0:\n",
    "                    V = abs(V)\n",
    "\n",
    "                V_anti = V_anti + kappa*(theta-V_anti)*dt + sigma *np.sqrt(V_anti)*np.sqrt(dt)*eta_v_anti\n",
    "                if V_anti < 0:\n",
    "                    V_anti = abs(V_anti)\n",
    "\n",
    "                #Heston underlying\n",
    "                S = S * math.exp((r-0.5*V)*dt + np.sqrt(V) * np.sqrt(dt)* eta_s)\n",
    "\n",
    "                S_anti = S_anti * math.exp((r_anti - 0.5*V_anti)*dt + np.sqrt(V_anti)*np.sqrt(dt)*eta_s_anti)\n",
    "\n",
    "            if y in years:\n",
    "                participation_remuneration = issue_price * np.maximum(0, premium_percentage * (1 + premium_gearing * ((S - S0)/S0)))\n",
    "\n",
    "                payoff += participation_remuneration\n",
    "\n",
    "                participation_remuneration_anti = issue_price * np.maximum(0, premium_percentage * (1 + premium_gearing * (S_anti - S0) / S0))\n",
    "\n",
    "                payoff_anti += participation_remuneration_anti\n",
    "\n",
    "            if y == maturity:\n",
    "                settlement_amount = np.minimum(cap_level, np.maximum(initial_percentage * S0, (S0 + 1 * (S - S0) * multiplier))) * 1\n",
    "\n",
    "                payoff += settlement_amount\n",
    "\n",
    "                settlement_amount_anti = np.minimum(cap_level, np.maximum(initial_percentage * S0, (S0 + 1 * (S_anti - S0) * multiplier))) * 1\n",
    "\n",
    "                payoff_anti += settlement_amount_anti\n",
    "\n",
    "\n",
    "            integral_r=(0.5*(r0-r) + sum_r) * dt\n",
    "            integral_r_anti = (0.5*(r0-r_anti) + sum_r_anti) * dt\n",
    "\n",
    "            discount_factor = np.exp(-integral_r)\n",
    "            discount_factor_anti = np.exp(-integral_r_anti)\n",
    "\n",
    "            discounted_payoffs = payoff * discount_factor\n",
    "            discounted_payoffs_anti = payoff_anti * discount_factor_anti\n",
    "\n",
    "        total_payoffs.append(discounted_payoffs)\n",
    "        total_payoffs_anti.append((discounted_payoffs_anti+discounted_payoffs)/2)\n",
    "\n",
    "    variance = np.std(total_payoffs)\n",
    "    variance_anti = np.std(total_payoffs_anti)\n",
    "\n",
    "    mean = np.mean(total_payoffs)\n",
    "    mean_anti = np.mean(total_payoffs_anti)\n",
    "\n",
    "    MC_error = np.sqrt(variance/M)\n",
    "    MC_error_anti = np.sqrt(variance_anti/M)\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Price with no variance reduction\", mean)\n",
    "    print(\"MC error with no variance reduction\", MC_error)\n",
    "    print(\"Price with antithetic\", mean_anti)\n",
    "    print(\"MC error with antithetic\", MC_error_anti)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we price our certificate and use the antithetic variance reduction, as we can see we got an improvement. Our variance has been reduced approximately by 0.15..."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price with no variance reduction 1154.9160090042665\n",
      "MC error with no variance reduction 0.963252145569879\n",
      "Price with antithetic 1162.201506114045\n",
      "MC error with antithetic 0.8114578072824989\n"
     ]
    }
   ],
   "source": [
    "MCS_antithetic(763.91, 1000, .02, 0.2, .03, .07, .2, 0.09, 0.4, 7, .5, 1000, 250)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The computation of the relevant Greeks are made using the centered finite difference, the only different formula is given by Gamma because it's the second derivative."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9396959965226841 3.8963305320694565e-15 -41.84059003466007 93.37252564475173 -2708.061585844632\n"
     ]
    }
   ],
   "source": [
    "#Implementation for delta and gamma greek\n",
    "delta_s = S0 * .01\n",
    "mean = MCS(763.91, 1000, .02, 0.2, .03, .07, .2, 0.09, 0.4, 7, .5, 1000, 250)\n",
    "s_up = S0 + delta_s\n",
    "s_down = S0 - delta_s\n",
    "price_d_up = MCS(s_up, 1000, .02, 0.2, .03, .07, .2, 0.09, 0.4, 7, .5, 1000, 250)\n",
    "price_d_down = MCS(s_down, 1000, .02, 0.2, .03, .07, .2, 0.09, 0.4, 7, .5, 1000, 250)\n",
    "\n",
    "#Implementation for theta\n",
    "delta_t = 1\n",
    "t_plus = maturity + 1\n",
    "t_minus = maturity - 1\n",
    "price_t_up = MCS(763.91, 1000, .02, 0.2, .03, .07, .2, 0.09, 0.4, t_plus, .5, 1000, 250)\n",
    "price_t_down = MCS(763.91, 1000, .02, 0.2, .03, .07, .2, 0.09, 0.4, t_minus, .5, 1000, 250)\n",
    "\n",
    "#Implementation for vega\n",
    "delta_v = math.sqrt(v0) * .01\n",
    "v_plus = (math.sqrt(v0) + delta_v)**2\n",
    "v_minus = (math.sqrt(v0) - delta_v)**2\n",
    "price_v_up = MCS(763.91, 1000, .02, 0.2, .03, .07, .2, 0.09, v_plus, 7, .5, 1000, 250)\n",
    "price_v_down = MCS(763.91, 1000, .02, 0.2, .03, .07, .2, 0.09, v_minus, 7, .5, 1000, 250)\n",
    "\n",
    "#Implementation for Rho\n",
    "delta_r = r0 * .01\n",
    "rho_plus = r0 + delta_r\n",
    "rho_minus = r0 - delta_r\n",
    "price_rho_up = MCS(763.91, 1000, rho_plus, 0.2, .03, .07, .2, 0.09, 0.4, 7, .5, 1000, 250)\n",
    "price_rho_down = MCS(763.91, 1000, rho_minus, 0.2, .03, .07, .2, 0.09, 0.4, 7, .5, 1000, 250)\n",
    "\n",
    "Delta = (price_d_up - price_d_down)/(2*delta_s)\n",
    "Gamma = (price_d_up - 2*mean + price_d_down) / (delta_s**2)\n",
    "Theta = -(price_t_up - price_t_down)/(2*delta_t)\n",
    "Vega = (price_v_up - price_v_down) / (2*delta_v)\n",
    "Rho = (price_rho_up - price_rho_down) / (delta_r*2)\n",
    "\n",
    "print(Delta, Gamma, Theta, Vega, Rho)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "-The value of Delta suggests us that the price of our certificate has a high sensitivity to changes in underlying asset's price, which is true because the investment return (coupons and settlement amount) are strictly related to the performance of the underlying. For every unit of change we have a change in certificated price by 0.9397 in the same direction.\n",
    "-The extremely low Gamma suggests us that the Delta is pretty much constant across a range of underlying asset price movements, as well has a really low sensitivity to changes in Delta.\n",
    "-Here a negative Theta tells us that time to decay, meaning the increase in time to maturity by 1 year, decreases the value of our certificate. This can be realted to the cap of our certificate, imagine the index has a drift of 2% every year. Obviosuly with increasing time the chances that the underlying go over the cap become higher and higher reducing our certificate price.\n",
    "-The increase of Vega by 1% has a positive impact other the certificate increasing the value by around 93$. This can be also true, because on the contrary of the stocks ,where 20% of standard deviation means increases and decreases of value by that percentage meaning they offset eachother, the options don't have a downside because we can choose not to exercise if the result gives us a loss. The certificate in our case has a barrier, so meaning it's similiar to options reality.\n",
    "-The Rho is too high, means that we have computed the calculation in a wrong way or the numerical approximation needs a more complex model in order to get out the Rho."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
